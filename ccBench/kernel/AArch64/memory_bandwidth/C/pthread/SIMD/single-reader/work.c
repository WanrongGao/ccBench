/******************************************************************************************************
 * BenchIT - Performance Measurement for Scientific Applications
 * Contact: developer@benchit.org
 *
 * $Id$
 * For license details see COPYING in the package base directory
 ******************************************************************************************************/
/* Kernel: measures read bandwidth of data located in different cache levels or memory of certain CPUs.
 ******************************************************************************************************/
 
/*
 * TODO  - check malloc and mmap return values for errors and abort if alocation of buffers fails
 *       - adopt cache and TLB parameters to refer to identifiers returned by 
 *         the hardware detection
 *       - optional global or local alloc of flush buffer
 *       - add manual instrumentation for VampirTracce
 *       - memory layout improvements (as for single-r1w1)
 */

#include "interface.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/time.h>
#include <time.h>
#include <math.h>
#include <pthread.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <sys/mman.h>
#include <assert.h>
#include <errno.h>
#include <unistd.h>
#include <limits.h>

#include "work.h"

#ifdef USE_PAPI
#include <papi.h>
#endif


/* user defined maximum value of random numbers returned by _random() */
static unsigned long long random_max=0;

/* parameters for random number generator 
 *  formula: random_value(n+1) = (rand_a*random_value(n)+rand_b)%rand_m
 *  rand_fix: rand_fix=(rand_a*rand_fix+rand_b)%rand_m
 *        - won't be used as start_value
 *        - can't be reached by random_value, however special care is taken that rand_fix will also be returned by _random()
 */
static unsigned long long random_value=0;
static unsigned long long rand_a=0;
static unsigned long long rand_b=0;
static unsigned long long rand_m=1;
static unsigned long long rand_fix=0;

/* table of prime numbers needed to generate parameters for random number generator */
int *p_list=NULL;
int p_list_max=0;
int pos=0;

/* variables for prime factorization needed to generate parameters for random number generator */
long long parts [64];
int part_count;
long long number;
int max_factor;

/** checks if value is prime
 *  has to be called with all prime numbers < sqrt(value)+1 prior to the call with value
 */
static int isprime(unsigned long long value)
{
  int i;
  int limit = (int) trunc(sqrt((double) value)) +1;
  for (i=0;i<=pos;i++){
      if (p_list[i]>limit) break;
      if (value==(unsigned long long)p_list[i]) return 1;
      if (value%p_list[i]==0) return 0;
  }
  if (pos < p_list_max -1){
     pos++;
     p_list[pos]=value;
  }
  else
   if (p_list[pos]<limit) 
      for (i=p_list[pos];i<=limit;i+=2){
        if (value%i==0) return 0;
      }
  return 1;
}

/** checks if value is a prime factor of global variable number
 *  has to be called with all prime numbers < sqrt(value)+1 prior to the call with value
 */
static int isfactor(int value)
{
  if (value<p_list[p_list_max-1]) if (!isprime(value)) return 0;
  if (number%value==0){
     parts[part_count]=value;
     while (number%value==0){
       number=number/value;
     }
     part_count++;
     max_factor = (int) trunc(sqrt((double) number))+1;
  }
  return 1;
}

/** calculates (x^y)%m
 */
static unsigned long long potenz(long long x, long long y, long long m)
{
   unsigned long long res=1,mask=1;

   if (y==0) return 1;if (y==1) return x%m;

   assert(y==(y&0x00000000ffffffffULL));
   assert(x==(x&0x00000000ffffffffULL));
   assert(m==(m&0x00000000ffffffffULL));
   
   mask = mask<<63;
   while ((y&mask)==0) mask= mask >> 1;
   do{
        if (y&mask){
            res=(res*x)%m;
            res=(res*res)%m;
        }
        else res=(res*res)%m;
        mask = mask >> 1;
   }
   while (mask>1);
   if (y&mask) res=(res*x)%m;

   return res;
}

/** checks if value is a primitive root of rand_m
 */
static int isprimitiveroot(long long value)
{
  long long i,x,y;
  for (i=0;i<part_count;i++){
      x = value;
      y = (rand_m-1)/parts[i];     
      if (potenz(x,y,rand_m)==1) return 0;
  }
  return 1;
}

/** returns a pseudo random number
 *  do not use this function without a prior call to _random_init()
 */
unsigned long long _random(void)
{
  if (random_max==0) return -1;
  do{
    random_value = (random_value * rand_a + rand_b)%rand_m;
  }
  while (((random_value>random_max)&&(rand_fix<random_max))||((random_value>=random_max)&&(rand_fix>=random_max)));
  /* hide fixpoint to ensure that each number < random_max is eventually returned (generate permutation of 0..random_max-1) */
  if (random_value<rand_fix) return random_value;
  else return random_value-1;
}

/** Initializes the random number generator with the values given to the function.
 *  formula: r(n+1) = (a*r(n)+b)%m
 *  sequence generated by calls of _random() is a permutation of values from 0 to max-1
 */
void _random_init(int start,int max)
{
  int i;
  unsigned long long x,f1,f2;

  random_max = (unsigned long long) max;
  if (random_max==0) return;
  /* allocate memory for prime number table */
  if ((((int) trunc(sqrt((double) random_max)) +1)/2+1)>p_list_max){
    p_list_max=((int) trunc(sqrt((double) random_max)) +1)/2+1;
    p_list=realloc(p_list,p_list_max*sizeof(int));
    if (p_list==NULL){
      while(p_list==NULL){
        p_list_max=p_list_max/2;
        p_list=calloc(p_list_max,sizeof(int));
        assert(p_list_max>2);
      }
      pos=0;
    }
    if (pos==0){
      p_list[0]=2;
      p_list[1]=3;
      pos++;
    }
  }

  /* setup parameters rand_m, rand_a, rand_b, and rand_fix*/
  rand_m=1;
  do{
    rand_m+=2;
    rand_a=0;

    /* find a prime number for rand_m, larger than random_max*/
    while ((pos<p_list_max-1)){rand_m+=2;isprime(rand_m);} /* fill prime number table */
    if (rand_m<=random_max) {rand_m=random_max+1;if(rand_m%2==0)rand_m++;}
    while (!isprime(rand_m)) rand_m+=2;
  
    /* set rand_b to a value between rand_m/4 and 3*rand_m/4 */
    rand_b=start%(rand_m/2)+rand_m/4;
    rand_b|=1; // avoid b=0 for m=3, ensures b is odd
  
    /* prime factorize rand_m-1, as those are good candidates for primitive roots of rand_m */
    number=rand_m-1;
    max_factor = (int) trunc(sqrt((double) number))+1;
    part_count=0;
    for(i=0;i<p_list_max;i++) isfactor(p_list[i]);
    i=p_list[p_list_max-1];
    while (i<max_factor){
       isfactor(i);
       i+=2;
    }
    if (number>1){
       parts[part_count]=number;
       part_count++;
    }
  
    /* find a value for rand_a that is a primitive root of rand_m and != rand_m/2 
     * rand_a = rand_m/2 has a high likelyhood to generate a regular pattern */
    for (i=0;i<part_count;i++){
      if ((rand_m/2!=parts[i])&&(parts[i]*parts[i]>rand_m)&&(isprimitiveroot(parts[i]))) {rand_a=parts[i];break;}
    }
    
    /* find fixpoint 
     * check all possibilities: fix = a * fix + b, fix = (a * fix + b) - m, fix = (a * fix +b) - 2m, ... , fix = (a * fix +b) - (a * m)
     * b is != 0, thus fix = a * fix + b (i.e., fix = 0) cannot happen 
     */
    rand_fix=0;
    if (rand_a!=0) for(x=1;x<=rand_a;x++){        // check for '- (n * m)' with 1 <= n <= a, '- (0 * m)' does not happen (see above)
        f1 = ((x*rand_m) -rand_b ) / (rand_a-1);  // f1 = (a * f1 + b) - (x * m) -> 0 = (a-1) * f1 + b - (x * m) -> f1 = ((x * m) -b) / (a - 1)
        f2 = ((f1*rand_a)+rand_b) % rand_m;       // check if f1 is the fixpoint (this only happens for the right x)
        if (f1==f2) {rand_fix=f1;break;}
    }    
  }
  /* condition 1 avoids small values for rand_a in order to generate highly fluctuating sequences,
   * condition 2 avoids that a combination of rand_m, rand_a, and rand_b is choosen that does not have a fixpoint (should never happen for prime rand_m)
   */
  while((rand_a*rand_a<rand_m)||(rand_fix==0));


  /* generator is initialized with the user defined start value */
  random_value= (unsigned long long)start%rand_m;
  if (random_value==rand_fix) random_value=0;  /* replace with 0 if it equals rand_fix */
}

/*
 * use a block of memory to ensure it is in the caches afterwards
 * MODE_EXCLUSIVE: - cache line will be exclusive in cache of calling CPU
 * MODE_MODIFIED:  - cache line will be modified in cache of calling CPU
 * MODE_INVALID:   - cache line will be invalid in all caches
 * MODE_SHARED/MODE_OWNED/MODE_FORWARD:
 *   - these modes perform a read-only access (on SHARE_CPU)
 *   - together with accesses on another CPU with MODE_{EXCLUSIVE|MODIFIED} cache line will be in the
 *     desired coherency state in the cache of the OTHER CPU, and SHARED in the cache of SHARE_CPU
 *     (see USE MODE ADAPTION in file work.c)
 */
static inline int use_memory(void* buffer,void* flush_buffer,unsigned long long memsize,int mode,int direction,int repeat,cpu_info_t cpuinfo)
{
   int i,j,tmp=0xd08a721b;
   unsigned long long stride = 64;

   for (i=cpuinfo.Cachelevels;i>0;i--)
   {
     if (cpuinfo.Cacheline_size[i-1]<stride) stride=cpuinfo.Cacheline_size[i-1];
   }

   if ((mode==MODE_MODIFIED)||(mode==MODE_EXCLUSIVE)||(mode==MODE_INVALID))
   {
     //invalidate remote caches
    	 __asm__ __volatile__
		(
       		"_use_mem_inv_loop:\n\t"
			"str %1,[%0]\n\t"
       		"add %0,%0,%2\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_inv_loop\n\t"
       		:
		: "r" ((unsigned long long)buffer), "r" (tmp), "r" (stride), "r" (memsize/stride)
		: "memory"
		);
     //invalidate local caches
     if (!cpuinfo.disable_clflush) clflush(buffer,memsize,cpuinfo);
     else {
             __asm__ __volatile__
		(
       		"_use_mem_flush_loop:\n\t"
			"str %1,[%0]\n\t"
       		"add %0,%0,%2\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_flush_loop\n\t"
       		:
       		: "r" ((unsigned long long)flush_buffer), "r" (tmp), "r" (stride), "r" (((cpuinfo.D_Cache_Size_per_Core*cpuinfo.EXTRA_FLUSH_SIZE)/50)/stride) : "memory");
	clflush(flush_buffer,(cpuinfo.D_Cache_Size_per_Core*cpuinfo.EXTRA_FLUSH_SIZE)/50,cpuinfo);
     }
   } 
   asm volatile ("dmb sy\n\t" : : : "memory");

   j=repeat;

   if (mode==MODE_MODIFIED)
   {
     while(j--)
     {
	if (direction==FIFO){
     __asm__ __volatile__
		(
       		"_use_mem_write_loop_fifo:\n\t"
			"str %1,[%0]\n\t"
       		"add %0,%0,%2\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_write_loop_fifo\n\t"
       		:
		: "r" ((unsigned long long)buffer), "r" (tmp), "r" (stride), "r" (memsize/stride)
		: "memory"
		);
       }
       //ok
       if (direction==LIFO){
    __asm__ __volatile__
		(
       		"_use_mem_write_loop_lifo:\n\t"
       		"sub %0, %0,%2\n\t"
			"str %1,[%0]\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_write_loop_lifo\n\t"
       		:
		: "r" ((unsigned long long)buffer+memsize), "r" (tmp), "r" (stride), "r" (memsize/stride)
		: "memory"
		);
       }
     }
   } 
 
   if ((mode==MODE_EXCLUSIVE)||(mode==MODE_SHARED)||(mode==MODE_OWNED)||(mode==MODE_FORWARD)||(mode==MODE_RDONLY)) 
   {
     while(j--)
     {
	if (direction==FIFO){
         __asm__ __volatile__(
       		"_use_mem_read_loop_fifo:\n\t"
			"ldr x4,[%1]\n\t"
       		"add %0,%0,x4\n\t"
       		"add %1,%1,%2\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_read_loop_fifo\n\t"
       		: "=&r" (tmp)
		: "r" ((unsigned long long)buffer), "r" (stride), "r" (memsize/stride)
		:"cc","x4"
		);
       }
       //ok
       if (direction==LIFO) {
         __asm__ __volatile__(
       		"_use_mem_read_loop_lifo:\n\t"
       		"sub %1,%1,%2\n\t"
			"ldr x4,[%1]\n\t"
       		"subs %3,%3,#1\n\t"
       		"bne _use_mem_read_loop_lifo\n\t"
       		: "=&r" (tmp)
		: "r" ((unsigned long long)buffer+memsize), "r" (stride), "r" (memsize/stride)
		:"cc","x4"
		);
     	}
     }
   }  
   
   asm volatile ("dmb sy\n\t" : : : "memory");

   return tmp;
}

/**
 * flushes data from the specified cachelevel
 * @param level the cachelevel that should be flushed
 * @param num_flushes number of accesses to each cacheline
 * @param mode MODE_EXCLUSIVE: fill cache with dummy data in state exclusive
 *             MODE_MODIFIED:  fill cache with dummy data in state modified (causes write backs of dirty data later on)
 *             MODE_INVALID:   invalidate cache (requires clflush)
 *             MODE_RDONLY:    fill cache with valid dummy data, does not perform any write operations, state can be exclusive or shared/forward
 * @param buffer pointer to a memory area, size of the buffer has to be 
 *               has to be larger than 2 x sum of all cachelevels <= level
 */
static inline int cacheflush(int level,int num_flushes,int mode,void* buffer,cpu_info_t cpuinfo)
{
  unsigned long long stride=cpuinfo.Cacheline_size[level-1]/num_flushes;
  unsigned long long size=0;
  int i,j,tmp=0x0fa38b09;

  if (level>cpuinfo.Cachelevels) return -1;

  //exclusive caches
  if (((!strcmp(cpuinfo.vendor,"AuthenticAMD")) && (cpuinfo.family != 21))||!strcmp(cpuinfo.vendor,"0x43"))
  //if ((!strcmp(cpuinfo.vendor,"AuthenticAMD")) && (cpuinfo.family != 21))
  for (i=0;i<level;i++)
  {
     if (cpuinfo.Cache_unified[i]) size+=cpuinfo.U_Cache_Size[i];
     else size+=cpuinfo.D_Cache_Size[i];
  }
  //inclusive L2, exclusive L3
  //if (((!strcmp(cpuinfo.vendor,"AuthenticAMD")) && (cpuinfo.family == 21))||!strcmp(cpuinfo.vendor,"0x43"))
  if ((!strcmp(cpuinfo.vendor,"AuthenticAMD")) && (cpuinfo.family == 21))
  {
    if (level<3)
    {
      i=level-1;
   	  if (cpuinfo.Cache_unified[i]) size=cpuinfo.U_Cache_Size[i];
      else size=cpuinfo.D_Cache_Size[i];
    }
    else for (i=1;i<level;i++)
    {     
     if (cpuinfo.Cache_unified[i]) size+=cpuinfo.U_Cache_Size[i];
     else size+=cpuinfo.D_Cache_Size[i];
    }
  }
  //inclusive caches
  if (!strcmp(cpuinfo.vendor,"GenuineIntel")||!strcmp(cpuinfo.vendor,"0x70")||!strcmp(cpuinfo.vendor,"0x48"))//FT,KP920
  {
     i=level-1;
     if (cpuinfo.Cache_unified[i]) size=cpuinfo.U_Cache_Size[i];
     else size=cpuinfo.D_Cache_Size[i];
  } 

  size*=cpuinfo.EXTRA_FLUSH_SIZE;
  // double amount of accessed memory for LLC flushes and decrease num_flushes
  if (level==cpuinfo.Cachelevels){ 
    size*=2;
    num_flushes/=3;
    num_flushes++;
  }
  size/=100;

  if (stride<sizeof(unsigned int)) stride=sizeof(unsigned int);
  
  if (mode!=MODE_RDONLY){
    j=num_flushes;
    while(j--)
    {
     for (i=0;i<size;i+=stride)
     {
       tmp|=*((int*)((unsigned long long)buffer+i));
       *((int*)((unsigned long long)buffer+i))=tmp;
     }
    }
  }
  if ((mode==MODE_EXCLUSIVE)||(mode==MODE_INVALID)){
    clflush(buffer,size,cpuinfo);
  }
  if ((mode==MODE_EXCLUSIVE)||(mode==MODE_RDONLY)){
    j=num_flushes;
    while(j--)
    {
     for (i=0;i<size;i+=stride)
     {
       tmp|=*((int*)((unsigned long long)buffer+i));
     }
     *((int*)((unsigned long long)buffer+i))=tmp;
    }
  }

  return tmp;
}


/*
 * flush all caches that are smaller than the specified memory size, including shared caches
 */
static inline void flush_caches(void* buffer,unsigned long long memsize,int settings,int num_flushes,int flush_mode,void* flush_buffer,cpu_info_t *cpuinfo)
{
   int i,j;
   unsigned long long total_cache_size;
   if (((!strcmp(cpuinfo->vendor,"AuthenticAMD")) && (cpuinfo->family != 21))||!strcmp(cpuinfo->vendor,"0x43")) //exclusive caches
  //if ((!strcmp(cpuinfo->vendor,"AuthenticAMD")) && (cpuinfo->family != 21)) //exclusive caches
   for (i=cpuinfo->Cachelevels;i>0;i--)
   {   
     if (settings&FLUSH(i))
     {
       // determine total exclusive cache size of level that should be flushed
       total_cache_size=0;
       for (j=i;j>0;j--) total_cache_size+=cpuinfo->U_Cache_Size[j-1]+cpuinfo->D_Cache_Size[j-1];
       // subtract higher levels that are flushed too as these flushes polute the cache and reduce the effectively usable size
       for (j=i-1;j>0;j--) if (settings&FLUSH(j)) total_cache_size-=cpuinfo->U_Cache_Size[j-1]+cpuinfo->D_Cache_Size[j-1];
       if(memsize>total_cache_size)
       {
         cacheflush(i,num_flushes,flush_mode,flush_buffer,*(cpuinfo));
         break;
       }
     }
   }
   else if ((!strcmp(cpuinfo->vendor,"AuthenticAMD")) && (cpuinfo->family == 21))//inclusive L2 cache, exclusive L3
      //else if (((!strcmp(cpuinfo->vendor,"AuthenticAMD")) && (cpuinfo->family == 21))||!strcmp(cpuinfo->vendor,"0x43"))//inclusive L2 cache, exclusive L3
   {
    for (i=cpuinfo->Cachelevels;i>2;i--)
    {   
     if (settings&FLUSH(i))
     {
       // determine total exclusive cache size of level that should be flushed
       total_cache_size=0;
       for (j=i;j>1;j--) total_cache_size+=cpuinfo->U_Cache_Size[j-1]+cpuinfo->D_Cache_Size[j-1];
       // subtract higher levels that are flushed too as these flushes polute the cache and reduce the effectively usable size
       if ((i==3) && (settings&FLUSH(2))) total_cache_size-=cpuinfo->U_Cache_Size[1]+cpuinfo->D_Cache_Size[1];
       else if ((i==3) && (settings&FLUSH(1))) total_cache_size-=cpuinfo->U_Cache_Size[0]+cpuinfo->D_Cache_Size[0];
       if(memsize>total_cache_size)
       {
         cacheflush(i,num_flushes,flush_mode,flush_buffer,*(cpuinfo));
         break;
       }
     }
    }
    for (i=2;i>0;i--)
    {   
     if ((settings&FLUSH(i))&&(memsize>(cpuinfo->U_Cache_Size[i-1]+cpuinfo->D_Cache_Size[i-1])))
     {
       cacheflush(i,num_flushes,flush_mode,flush_buffer,*(cpuinfo));
       break;
     }
    }
   }
   else // inclusive caches
   for (i=cpuinfo->Cachelevels;i>0;i--)
   {   
     if ((settings&FLUSH(i))&&(memsize>(cpuinfo->U_Cache_Size[i-1]+cpuinfo->D_Cache_Size[i-1])))
     {
       cacheflush(i,num_flushes,flush_mode,flush_buffer,*(cpuinfo));
       break;
     }
   }
}



/* measure overhead of empty loop */
int asm_loop_overhead(int n)
{
   unsigned long long a,b,c,d,i;
   static unsigned long long ret=1000000;

   for (i=0;i<n;i++){
        /* Output: RAX: stop timestamp 
         *         RBX: start timestamp
         */
        __asm__ __volatile__(
               //"mov $1,%%rcx;"
                TIMESTAMP
                SERIALIZE
		"mov %1,%0\n\t"
//                "jmp _work_loop_overhead;"
//                ".align 64,0x0;"
//                "_work_loop_overhead:"
//                "sub $1,%%rcx;"
//                "jnz _work_loop_overhead;"
                SERIALIZE
                TIMESTAMP
		: "=r"(a),"=r" (b)
        );
	if ((a-b)<ret) ret=(a-b);
   }			
  return (int)ret;
}

/** assembler implementation of bandwidth measurement using ld1 instruction
 */
static double asm_work_ld1(unsigned long long addr, unsigned long long accesses, unsigned long long burst_length, unsigned long long call_latency,unsigned long long freq,volatile mydata_t *data) __attribute__((noinline));
static double asm_work_ld1(unsigned long long addr, unsigned long long accesses, unsigned long long burst_length, unsigned long long call_latency,unsigned long long freq,volatile mydata_t *data)
{
   unsigned long long passes;
   double ret;
   int i;

   #ifdef USE_PAPI
    if (data->num_events) PAPI_reset(data->Eventset);
   #endif
   switch (burst_length)
   {

    case 1:
      passes=accesses/64;
      if (!passes) return 0;
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
                "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                TIMESTAMP
                SERIALIZE
                "b _work_loop_ld1_1\n\t"
                ".align 6\n\t"
                "_work_loop_ld1_1:\n\t"
                //PREFETCH(LINE_PREFETCH,0,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,64,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,128,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,192,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,256,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFET5CH,320,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,384,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,448,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,512,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,576,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,640,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,704,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,768,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,832,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,896,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,960,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		//"add %1,%1,#1024\n\t"
		"subs %2,%2,#1\n\t"
                "bne _work_loop_ld1_1\n\t"
                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=r" (addr)
                : "r"(addr), "r" (passes)
          //      : "q0"

      );
      ret=(((double)(passes*64*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;

    case 2:
      passes=accesses/64;
      if (!passes) return 0;
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
                "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                TIMESTAMP
                SERIALIZE
                "b _work_loop_ld1_2\n\t"
                ".align 6\n\t"
                "_work_loop_ld1_2:\n\t"
                                //PREFETCH(LINE_PREFETCH,0,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,64,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,128,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,192,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,256,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFET5CH,320,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,384,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,448,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,512,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,576,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,640,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,704,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,768,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,832,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,896,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,960,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		//"add %1,%1,#1024\n\t"
		"subs %2,%2,#1\n\t"
                "bne _work_loop_ld1_2\n\t"
                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=r" (addr)
                : "r"(addr), "r" (passes)
              //  : "q0","q1"
      );
      ret=(((double)(passes*64*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;

    case 3:
      passes=accesses/66;
      if (!passes) return 0;
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
                "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                TIMESTAMP
                SERIALIZE
                "b _work_loop_ld1_3\n\t"
                ".align 6\n\t"
                "_work_loop_ld1_3:\n\t"
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,64,rbx)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,128,rbx)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,192,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,256,rbx)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFET5CH,320,rbx)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,384,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,448,rbx)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,512,rbx)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,576,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,640,rbx)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,704,rbx)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,768,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,832,rbx)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,896,rbx)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,960,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)

		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		//"add %1,%1,#1056\n\t"
		"subs %2,%2,#1\n\t"
                "bne _work_loop_ld1_3\n\t"

                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=r" (addr)
                : "r"(addr), "r" (passes)
               // : "q0","q1","q2"

      );
      ret=(((double)(passes*66*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;

    case 4:
      passes=accesses/64;
      if (!passes) return 0;
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
                "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                TIMESTAMP
                SERIALIZE
                "b _work_loop_ld1_4\n\t"
                ".align 6\n\t"
                "_work_loop_ld1_4:\n\t"
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,64,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,128,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,192,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,256,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFET5CH,320,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,384,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,448,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,512,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,576,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,640,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,704,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,768,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,832,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,896,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,960,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		//"add %1,%1,#1024\n\t"
		"subs %2,%2,#1\n\t"
                "bne _work_loop_ld1_4\n\t"

                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=r" (addr)
                : "r"(addr), "r" (passes)
            //    : "q0","q1","q2","q3"

      );
      ret=(((double)(passes*64*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;

    case 8:
      passes=accesses/64;
      if (!passes) return 0;
  //    printf("enter measure 8!!!!!!!!!!!!!!!!\n");
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
               "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
	        TIMESTAMP
                SERIALIZE
                "b _work_loop_ld1_8\n\t"
                ".align 6\n\t"
                "_work_loop_ld1_8:\n\t"

//ld1
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,64,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,128,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,192,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,256,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFET5CH,320,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,384,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,448,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,512,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,576,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,640,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,704,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
               // PREFETCH(LINE_PREFETCH,768,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
              //  PREFETCH(LINE_PREFETCH,832,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,896,rbx)
		"ld1 {v0.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v1.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v2.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v3.4s},[%1],#16\n\t"NOP(NOPCOUNT)
             //   PREFETCH(LINE_PREFETCH,960,rbx)
		"ld1 {v4.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v5.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v6.4s},[%1],#16\n\t"NOP(NOPCOUNT)
		"ld1 {v7.4s},[%1],#16\n\t"NOP(NOPCOUNT)

		"subs %2,%2,#1\n\t"
                "bne _work_loop_ld1_8\n\t"

                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=&r" (addr)
                : "r"(addr), "r" (passes)

      );
      ret=(((double)(passes*64*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;
    default: ret=0.0;break;
   }

  #ifdef USE_PAPI
    if (data->num_events) PAPI_read(data->Eventset,data->values);
  #endif
    return ret;
}


/** assembler implementation of bandwidth measurement using ld1 instruction
 */
static double asm_work_ldr128(unsigned long long addr, unsigned long long accesses, unsigned long long burst_length, unsigned long long call_latency,unsigned long long freq,volatile mydata_t *data) __attribute__((noinline));
static double asm_work_ldr128(unsigned long long addr, unsigned long long accesses, unsigned long long burst_length, unsigned long long call_latency,unsigned long long freq,volatile mydata_t *data)
{
   unsigned long long passes;
   double ret;
   int i;

   #ifdef USE_PAPI
    if (data->num_events) PAPI_reset(data->Eventset);
   #endif
   switch (burst_length)
   {
    case 8:
      passes=accesses/64;
      if (!passes) return 0;
      /*
       * Input:  RBX: addr (pointer to the buffer)
       *         RCX: passes (number of loop iterations)
       * Output: RAX: stop timestamp - start timestamp
       */
      __asm__ __volatile__(
               "sub sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
	        TIMESTAMP
                SERIALIZE
                "b _work_loop_ldr128_8\n\t"
                ".align 6\n\t"
                "_work_loop_ldr128_8:\n\t"

//ldr 128
		"ldr q0,[%1,#0]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#16]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#32]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#48]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#64]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#80]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#96]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#112]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#128]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#144]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#160]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#176]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#192]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#208]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#224]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#240]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#256]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#272]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#288]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#304]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#320]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#336]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#352]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#368]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#384]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#400]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#416]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#432]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#448]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#464]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#480]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#496]\n\t"NOP(NOPCOUNT)

		"add %1,%1,#512\n\t"

		"ldr q0,[%1,#0]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#16]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#32]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#48]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#64]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#80]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#96]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#112]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#128]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#144]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#160]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#176]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#192]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#208]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#224]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#240]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#256]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#272]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#288]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#304]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#320]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#336]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#352]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#368]\n\t"NOP(NOPCOUNT)

		"ldr q0,[%1,#384]\n\t"NOP(NOPCOUNT)
		"ldr q1,[%1,#400]\n\t"NOP(NOPCOUNT)
		"ldr q2,[%1,#416]\n\t"NOP(NOPCOUNT)
		"ldr q3,[%1,#432]\n\t"NOP(NOPCOUNT)

		"ldr q4,[%1,#448]\n\t"NOP(NOPCOUNT)
		"ldr q5,[%1,#464]\n\t"NOP(NOPCOUNT)
		"ldr q6,[%1,#480]\n\t"NOP(NOPCOUNT)
		"ldr q7,[%1,#496]\n\t"NOP(NOPCOUNT)

		"add %1,%1,#512\n\t"

		"subs %2,%2,#1\n\t"
                "bne _work_loop_ldr128_8\n\t"

                SERIALIZE
		"mov %1,%0\n\t"
                TIMESTAMP
		"sub %0,%0,%1\n\t"
		"add sp,sp,#16\n\t"	//fix unexplainable stack pointer bug
                : "=&r" (addr)
                : "r"(addr), "r" (passes)

      );
      ret=(((double)(passes*64*16))/((double)(((addr)-call_latency))/(((double)freq)*0.000000001)));
      break;
    default: ret=0.0;break;
   }

  #ifdef USE_PAPI
    if (data->num_events) PAPI_read(data->Eventset,data->values);
  #endif
    return ret;
}


/** function that performs the measurement
 *   - entry point for BenchIT framework (called by bi_entry())
 */
void  _work( unsigned long long memsize, int offset, int function, int burst_length, int runs, volatile mydata_t* data, double **results)
{
  int loop_overhead,i,j,t;
  double tmax;
  double tmp=(double)0;
  unsigned long long tmp2,tmp3;
  int dtsize,max_threads;
  unsigned long long aligned_addr,accesses;
  #ifdef USE_PAPI
  int count;
  #endif

  aligned_addr=(unsigned long long)(data->buffer) + offset;

  switch (function) {
    case 1: dtsize = 32; break;
    case 3: dtsize = 32; break;
    case 4: dtsize = 8; break;
    default: dtsize = 16; break;
  }
  accesses = memsize / dtsize;
  if ((data->settings)&LOOP_OVERHEAD_COMP) loop_overhead=data->loop_overhead;
  else loop_overhead=data->cpuinfo->rdtsc_latency;

  if (accesses<512) runs*=5;
  else if (accesses<1024) runs*=3;
  else if (accesses<4096) runs*=2;
  if (memsize>data->cpuinfo->Total_D_Cache_Size) runs/=3;
  if (runs==0) runs=1;

  max_threads=data->num_results;
  for (t=0;t<max_threads;t++)
  {
   tmax=0;
  
   if(!t) aligned_addr=(unsigned long long)(data->buffer) + offset;
   else aligned_addr=data->threaddata[t].aligned_addr;
  
   if (accesses) 
   {
    for (i=0;i<runs;i++)
    {
    /* USE MODE ADAPTION (for BENCHIT_KERNEL_*_USE_MODE={S|F|O})
     * enforcing data to be in one of the shared coherency states (SHARED/OWNED/FORWARD), is implemented by adapting the target state for
     * individual accesses (a specific core (BENCHIT_KERNEL_SHARE_CPU) is used to share cachelines with the currently selected CPU (thread_id))
     * Forward: - Thread on SHARE_CPU accesses data with use mode EXCLUSIVE
     *          - Thread on selected CPU accesses data with use mode FORWARD (read only)
     *          Note: Forward seems to be a per-package state
     *                - Cores will have the line in shared state
     *                - L3 will have it in shared state (and 2 core valid bits set) if both cores share a package (die)
     *                - only if cores are in different packacges (dies), one L3 (last accessing core determines which one) will mark the line with state Forward
     *          Note: only usefull if coherency protocol is MESIF !!!
     * Shared:  - Thread on selected CPU accesses data with use mode EXCLUSIVE
     *          - Thread on SHARE_CPU accesses data with use mode SHARED (read only)
     *          Note: works on MESIF and non-MESIF protocols (copy on SHARE_CPU will be in Forward state for MESIF, thus SHRAE_CPU should be as far away from first CPU as posible)
     * Owned:   - Thread on selected CPU accesses data with use mode MODIFIED
     *          - Thread on SHARE_CPU accesses data with use mode SHARED (read only)
     *          Note: only works if coherency protocol is MOESI (otherwise both lines will be in shared state)
     */
      if ((data->USE_MODE==MODE_FORWARD)){
        //tell other threads to use memory
        unsigned long long tmp;
        int i;

        for (i=data->FRST_SHARE_CPU;i<data->FRST_SHARE_CPU+data->NUM_SHARED_CPUS;i++){
          tmp=data->threaddata[i].aligned_addr;
          if (t) data->threaddata[i].aligned_addr=data->threaddata[t].aligned_addr;
          else data->threaddata[i].aligned_addr=aligned_addr;
          data->threaddata[i].memsize=memsize;
          data->threaddata[i].accesses=accesses;
          if (i==data->FRST_SHARE_CPU) data->threaddata[i].USE_MODE=MODE_EXCLUSIVE;
          else data->threaddata[i].USE_MODE=data->USE_MODE;
          asm volatile ("dmb sy\n\t" : : : "memory");

          data->thread_comm[i]=THREAD_USE_MEMORY;
          while (!data->ack);
          data->ack=0;
          data->thread_comm[i]=THREAD_WAIT;    
          //wait for other thread using the memory
          while (!data->ack); //printf("wait for ack 1\n");
          data->ack=0;
          while (!data->done); //printf("wait for done 1\n");
          data->done=0;
          data->threaddata[i].aligned_addr=tmp;
        }
      }

      if (data->USE_MODE==MODE_MUW){
        //tell another thread to use memory
        unsigned long long tmp;
        tmp=data->threaddata[data->FRST_SHARE_CPU].aligned_addr;
        if (t) data->threaddata[data->FRST_SHARE_CPU].aligned_addr=data->threaddata[t].aligned_addr;
        else data->threaddata[data->FRST_SHARE_CPU].aligned_addr=aligned_addr;
        data->threaddata[data->FRST_SHARE_CPU].memsize=memsize;
        data->threaddata[data->FRST_SHARE_CPU].accesses=accesses;
        data->threaddata[data->FRST_SHARE_CPU].USE_MODE=MODE_MODIFIED; // -> M in SHARE_CPU, next read results in MUW in the requestor
        asm volatile ("dmb sy\n\t" : : : "memory");

        data->thread_comm[data->FRST_SHARE_CPU]=THREAD_USE_MEMORY;
        while (!data->ack);
        data->ack=0;
        data->thread_comm[data->FRST_SHARE_CPU]=THREAD_WAIT;    
        //wait for other thread using the memory
        while (!data->ack); //printf("wait for ack 1\n");
        data->ack=0;
        while (!data->done); //printf("wait for done 1\n");
        data->done=0;
        data->threaddata[data->FRST_SHARE_CPU].aligned_addr=tmp;
      }
      /* 
       * modified/exclusive: create copy with the requested state in target CPU (CPUs in SHARED_CPU_LIST not involved)
       * shared: create exclussive copy in target CPU first, will be transformed to shared by later accesses of CPUs in SHARED_CPU_LIST
       * forward: one exclusive or multiple shared copies already exist in CPUs from SHARED_CPU_LIST, additional read inserts forward copy in target CPU
       */    
      if (!t){ // measure local cache hierarchy      
        //access whole buffer to warm up cache
        if ((data->USE_MODE==MODE_SHARED)) use_memory((void*)aligned_addr,data->cache_flush_area,memsize,MODE_EXCLUSIVE,data->USE_DIRECTION,data->NUM_USES,*(data->cpuinfo));
        else if ((data->USE_MODE==MODE_MUW)) use_memory((void*)aligned_addr,data->cache_flush_area,memsize,MODE_SHARED,data->USE_DIRECTION,data->NUM_USES,*(data->cpuinfo));
        else if ((data->USE_MODE==MODE_OWNED)) use_memory((void*)aligned_addr,data->cache_flush_area,memsize,MODE_MODIFIED,data->USE_DIRECTION,data->NUM_USES,*(data->cpuinfo));
        else use_memory((void*)aligned_addr,data->cache_flush_area,memsize,data->USE_MODE,data->USE_DIRECTION,data->NUM_USES,*(data->cpuinfo));
      }
      else{ // measure accesses to other cores' caches
        //tell other thread to use memory
        data->threaddata[t].memsize=memsize;
        data->threaddata[t].accesses=accesses;
        if ((data->USE_MODE==MODE_SHARED)) data->threaddata[t].USE_MODE=MODE_EXCLUSIVE;
        else if ((data->USE_MODE==MODE_MUW)) data->threaddata[t].USE_MODE=MODE_SHARED;
        else if ((data->USE_MODE==MODE_OWNED)) data->threaddata[t].USE_MODE=MODE_MODIFIED; 
        else data->threaddata[t].USE_MODE=data->USE_MODE;
        asm volatile ("dmb sy\n\t" : : : "memory");

        data->thread_comm[t]=THREAD_USE_MEMORY;
        while (!data->ack);
        data->ack=0;
        data->thread_comm[t]=THREAD_WAIT;    
        //wait for other thread using the memory
        while (!data->ack); //printf("wait for ack 2\n");
        data->ack=0;
        while (!data->done);//printf("wait for done 2\n");
        data->done=0;             
      }
 
      /* turn Exclusive copy in target CPU into Shared copy
       * one CPU in SHARED_CPU_LIST will have forward copy
       */       
      if (data->USE_MODE==MODE_SHARED){
        //tell other threads to use memory
        unsigned long long tmp;
        int i;

        for (i=data->FRST_SHARE_CPU;i<data->FRST_SHARE_CPU+data->NUM_SHARED_CPUS;i++){
          tmp=data->threaddata[i].aligned_addr;
          if (t) data->threaddata[i].aligned_addr=data->threaddata[t].aligned_addr;
          else data->threaddata[i].aligned_addr=aligned_addr;
          data->threaddata[i].memsize=memsize;
          data->threaddata[i].accesses=accesses;
          data->threaddata[i].USE_MODE=data->USE_MODE;
          asm volatile ("dmb sy\n\t" : : : "memory");

          data->thread_comm[i]=THREAD_USE_MEMORY;
          while (!data->ack);
          data->ack=0;
          data->thread_comm[i]=THREAD_WAIT;    
          //wait for other thread using the memory
          while (!data->ack); //printf("wait for ack 3\n");
          data->ack=0;
          while (!data->done); //printf("wait for done 3\n");
          data->done=0;
          data->threaddata[i].aligned_addr=tmp;
        }
      }
      if (data->USE_MODE==MODE_OWNED){
        //tell another thread to use memory
        unsigned long long tmp;
        tmp=data->threaddata[data->FRST_SHARE_CPU].aligned_addr;
        if (t) data->threaddata[data->FRST_SHARE_CPU].aligned_addr=data->threaddata[t].aligned_addr;
        else data->threaddata[data->FRST_SHARE_CPU].aligned_addr=aligned_addr;
        data->threaddata[data->FRST_SHARE_CPU].memsize=memsize;
        data->threaddata[data->FRST_SHARE_CPU].accesses=accesses;
        data->threaddata[data->FRST_SHARE_CPU].USE_MODE=data->USE_MODE;
        asm volatile ("dmb sy\n\t" : : : "memory");

        data->thread_comm[data->FRST_SHARE_CPU]=THREAD_USE_MEMORY;
        while (!data->ack);
        data->ack=0;
        data->thread_comm[data->FRST_SHARE_CPU]=THREAD_WAIT;    
        //wait for other thread using the memory
        while (!data->ack); //printf("wait for ack 5\n");
        data->ack=0;
        while (!data->done); //printf("wait for done 5\n");
        data->done=0;
        data->threaddata[data->FRST_SHARE_CPU].aligned_addr=tmp;
      }

      //flush cachelevels as specified in PARAMETERS
      //tell threads on shared CPUs to flush caches  
      for (j=data->FRST_SHARE_CPU;j<data->FRST_SHARE_CPU+data->NUM_SHARED_CPUS;j++){
         if (data->flush_share_cpu) data->thread_comm[j]=THREAD_FLUSH_ALL;
         else data->thread_comm[j]=THREAD_FLUSH;
         while (!data->ack);
         data->ack=0;
         data->thread_comm[j]=THREAD_WAIT;    
         //wait for other thread flushing their caches
         while (!data->ack); //printf("wait for ack 6\n");
         data->ack=0;       
      }     
      if (t){
         //tell thread on target CPU to flush caches
         data->thread_comm[t]=THREAD_FLUSH;
         while (!data->ack);
         data->ack=0;
         data->thread_comm[t]=THREAD_WAIT;    
         //wait for other thread flushing their caches
         while (!data->ack); //printf("wait for ack 6\n");
         data->ack=0;
         if (data->settings&OPT_FLUSH_CPU0) flush_caches((void*) data->threaddata[t].aligned_addr,memsize,data->settings,data->NUM_FLUSHES,data->FLUSH_MODE,data->cache_flush_area,data->cpuinfo);
      }
      else flush_caches((void*) data->threaddata[t].aligned_addr,memsize,data->settings,data->NUM_FLUSHES,data->FLUSH_MODE,data->cache_flush_area,data->cpuinfo);

     /* call ASM implementation */
    switch(function){
       case 0://ld1
         //prefetch measurement routine
         if (data->ENABLE_CODE_PREFETCH)
           for (j=0;j<data->NUM_USES;j++) {tmp+=asm_work_ld1((unsigned long long)(data->cache_flush_area),48,burst_length,loop_overhead,data->cpuinfo->clockrate,data);}
         //measurement
         tmp=asm_work_ld1(aligned_addr,accesses,burst_length,loop_overhead,data->cpuinfo->clockrate,data);break;
       case 1://ldr128
         //prefetch measurement routine
         if (data->ENABLE_CODE_PREFETCH)
           for (j=0;j<data->NUM_USES;j++) {tmp+=asm_work_ldr128((unsigned long long)(data->cache_flush_area),48,burst_length,loop_overhead,data->cpuinfo->clockrate,data);}
         //measurement
         tmp=asm_work_ldr128(aligned_addr,accesses,burst_length,loop_overhead,data->cpuinfo->clockrate,data);break;
       default: break;
     }
      if ((int)tmp!=-1){
       if (tmp>tmax)
       {
         tmax=tmp;
         #ifdef USE_PAPI
         switch (burst_length)
         {
           case 1: count = 1024 / dtsize; break;
           case 2: count = 1024 / dtsize; break;
           case 3: count = 1056 / dtsize; break;
           case 4: count = 1024 / dtsize; break;
           case 8: count = 1024 / dtsize; break;
         }

         for (i=0;i<data->num_events;i++)
         {
            data->papi_results[i*max_threads+t]=(double)data->values[i]/(double)((accesses/count)*count);
         }
         #endif
       }
     }
    }
   }
   else tmax=0;
  
   if (tmax) (*results)[t]=tmax;
   else (*results)[t]=INVALID_MEASUREMENT;
  }
}


/** loop for additional worker threads
 *  communicating with master thread using shared variables
 */
void *thread(void *threaddata)
{
  int id= ((threaddata_t *) threaddata)->thread_id;
  unsigned int numa_node;
  struct bitmask *numa_bitmask;
  volatile mydata_t* global_data = ((threaddata_t *) threaddata)->data; //communication
  threaddata_t* mydata = (threaddata_t*)threaddata;
  char* filename=NULL;

  struct timespec wait_ns;
  int j,k,fd;
  double tmp=(double)0;
  unsigned long long i,tmp2,tmp3,old=THREAD_STOP;
  
  wait_ns.tv_sec=0;
  wait_ns.tv_nsec=100000;
  
  do
  {
   old=global_data->thread_comm[id];
  }
  while (old!=THREAD_INIT);
  global_data->ack=id;

  cpu_set(((threaddata_t *) threaddata)->mem_bind);
  numa_node = numa_node_of_cpu(((threaddata_t *) threaddata)->mem_bind);
  numa_bitmask = numa_bitmask_alloc((unsigned int) numa_max_possible_node());
  numa_bitmask = numa_bitmask_clearall(numa_bitmask);
  numa_bitmask = numa_bitmask_setbit(numa_bitmask, numa_node);
  numa_set_membind(numa_bitmask);
  numa_bitmask_free(numa_bitmask);

  if(mydata->buffersize)
  {
    if (global_data->hugepages==HUGEPAGES_OFF) mydata->buffer = (void *) _mm_malloc( mydata->buffersize,mydata->alignment);
    if (global_data->hugepages==HUGEPAGES_ON)
    {
      char *dir;
      dir=bi_getenv("BENCHIT_KERNEL_HUGEPAGE_DIR",0);
      filename=(char*)malloc((strlen(dir)+20)*sizeof(char));
      sprintf(filename,"%s/thread_data_%i",dir,id);
      mydata->buffer=NULL;
      fd=open(filename,O_CREAT|O_RDWR,0664);
      if (fd == -1)
      {
        fprintf( stderr, "Allocation of buffer failed\n" ); fflush( stderr );
        perror("open");
        exit( 127 );
      } 
      mydata->buffer=(char*) mmap(NULL,mydata->buffersize,PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);
      close(fd);unlink(filename);
    } 
    //fill buffer
   /* initialize buffer */
   tmp=sizeof(unsigned long long);
   for (i=0;i<=mydata->buffersize-tmp;i+=tmp){
      *((unsigned long long*)((unsigned long long)mydata->buffer+i))=(unsigned long long)i;
   }

    clflush(mydata->buffer,mydata->buffersize,*(mydata->cpuinfo));
    mydata->aligned_addr=(unsigned long long)(mydata->buffer) + mydata->offset;
  }
  else mydata->aligned_addr=(unsigned long long)(global_data->buffer) + mydata->offset; 

  cpu_set(((threaddata_t *) threaddata)->cpu_id);
  while(1)
  {
     switch (global_data->thread_comm[id]){
       case THREAD_USE_MEMORY: 
         if (old!=THREAD_USE_MEMORY)
         {
           old=THREAD_USE_MEMORY;
           global_data->ack=id;

           // use memory
           use_memory((void*)mydata->aligned_addr,mydata->cache_flush_area,mydata->memsize,mydata->USE_MODE,mydata->USE_DIRECTION,mydata->NUM_USES,*(mydata->cpuinfo));
           global_data->done=id;
         }
         else 
         {
           tmp=100;while(tmp>0) tmp--; 
         }        
         break;
       case THREAD_FLUSH: 
         if (old!=THREAD_FLUSH)
         {
           old=THREAD_FLUSH;
           global_data->ack=id;

           //flush cachelevels as specified in PARAMETERS
           flush_caches((void*) (mydata->aligned_addr),mydata->memsize,mydata->settings,mydata->NUM_FLUSHES,mydata->FLUSH_MODE,mydata->cache_flush_area,mydata->cpuinfo);
         }
         else 
         {
           tmp=100;while(tmp>0) tmp--; 
         }        
         break;
       case THREAD_FLUSH_ALL: 
         if (old!=THREAD_FLUSH_ALL)
         {
           old=THREAD_FLUSH_ALL;
           global_data->ack=id;

           //flush all caches
           flush_caches((void*) (mydata->aligned_addr),mydata->cpuinfo->Total_D_Cache_Size*2,mydata->settings,mydata->NUM_FLUSHES,mydata->FLUSH_MODE,mydata->cache_flush_area,mydata->cpuinfo);
         }
         else 
         {
           tmp=100;while(tmp>0) tmp--; 
         }        
         break;
       case THREAD_WAIT: // waiting
          if (old!=THREAD_WAIT) {
             global_data->ack=id;old=THREAD_WAIT;
          }
          tmp=100;while(tmp) tmp--; 
          break;
       case THREAD_INIT: // used for parallel initialisation only
          tmp=100;while(tmp) tmp--; 
          break;
       case THREAD_STOP: // exit
       default:
         if (global_data->hugepages==HUGEPAGES_ON)
         {
           if(mydata->buffer!=NULL) munmap((void*)mydata->buffer,mydata->buffersize);
         }
         pthread_exit(NULL);
    }
  }
}


